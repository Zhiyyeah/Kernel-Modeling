"""
åˆ†æè®­ç»ƒæ—¥å¿—æ–‡ä»¶ï¼Œæ£€æŸ¥è®­ç»ƒç¨³å®šæ€§
"""
import os
import csv
import numpy as np
import matplotlib.pyplot as plt

def load_training_log(log_file):
    """åŠ è½½è®­ç»ƒæ—¥å¿—"""
    iterations = []
    loss_d = []
    loss_g_adv = []
    loss_reg = []
    
    if not os.path.exists(log_file):
        print(f" æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {log_file}")
        return None
    
    with open(log_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            iterations.append(int(row['Iteration']))
            loss_d.append(float(row['Loss_D']))
            loss_g_adv.append(float(row['Loss_G_adv']))
            loss_reg.append(float(row['Loss_Reg']))
    
    return {
        'iterations': np.array(iterations),
        'loss_d': np.array(loss_d),
        'loss_g_adv': np.array(loss_g_adv),
        'loss_reg': np.array(loss_reg)
    }

def analyze_stability(data):
    """åˆ†æè®­ç»ƒç¨³å®šæ€§"""
    print("\n" + "="*70)
    print("ğŸ“Š è®­ç»ƒç¨³å®šæ€§åˆ†æ")
    print("="*70)
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"\nâœ“ æ€»è¿­ä»£æ¬¡æ•°: {len(data['iterations'])}")
    
    # Loss_D åˆ†æ
    print(f"\nğŸ“ˆ åˆ¤åˆ«å™¨æŸå¤± (Loss_D):")
    print(f"   å¹³å‡å€¼: {data['loss_d'].mean():.6f}")
    print(f"   æ ‡å‡†å·®: {data['loss_d'].std():.6f}")
    print(f"   æœ€å°å€¼: {data['loss_d'].min():.6f}")
    print(f"   æœ€å¤§å€¼: {data['loss_d'].max():.6f}")
    
    # Loss_G_adv åˆ†æ
    print(f"\nğŸ“ˆ ç”Ÿæˆå™¨å¯¹æŠ—æŸå¤± (Loss_G_adv):")
    print(f"   å¹³å‡å€¼: {data['loss_g_adv'].mean():.6f}")
    print(f"   æ ‡å‡†å·®: {data['loss_g_adv'].std():.6f}")
    print(f"   æœ€å°å€¼: {data['loss_g_adv'].min():.6f}")
    print(f"   æœ€å¤§å€¼: {data['loss_g_adv'].max():.6f}")
    
    # Loss_Reg åˆ†æ
    print(f"\nğŸ“ˆ æ ¸æ­£åˆ™åŒ–æŸå¤± (Loss_Reg):")
    print(f"   å¹³å‡å€¼: {data['loss_reg'].mean():.6f}")
    print(f"   æ ‡å‡†å·®: {data['loss_reg'].std():.6f}")
    print(f"   æœ€å°å€¼: {data['loss_reg'].min():.6f}")
    print(f"   æœ€å¤§å€¼: {data['loss_reg'].max():.6f}")
    
    # è¶‹åŠ¿åˆ†æ (ä½¿ç”¨ååŠéƒ¨åˆ†ä¸å‰åŠéƒ¨åˆ†çš„æ¯”è¾ƒ)
    mid_point = len(data['iterations']) // 2
    first_half_d = data['loss_d'][:mid_point]
    second_half_d = data['loss_d'][mid_point:]
    first_half_g = data['loss_g_adv'][:mid_point]
    second_half_g = data['loss_g_adv'][mid_point:]
    first_half_r = data['loss_reg'][:mid_point]
    second_half_r = data['loss_reg'][mid_point:]
    
    print(f"\nğŸ“Š å‰åæœŸå¯¹æ¯”:")
    print(f"   Loss_D: å‰æœŸå¹³å‡={first_half_d.mean():.6f}, åæœŸå¹³å‡={second_half_d.mean():.6f}")
    d_trend = (second_half_d.mean() - first_half_d.mean()) / first_half_d.mean() * 100
    print(f"           å˜åŒ–è¶‹åŠ¿: {d_trend:+.2f}%")
    
    print(f"   Loss_G_adv: å‰æœŸå¹³å‡={first_half_g.mean():.6f}, åæœŸå¹³å‡={second_half_g.mean():.6f}")
    g_trend = (second_half_g.mean() - first_half_g.mean()) / first_half_g.mean() * 100
    print(f"              å˜åŒ–è¶‹åŠ¿: {g_trend:+.2f}%")
    
    print(f"   Loss_Reg: å‰æœŸå¹³å‡={first_half_r.mean():.6f}, åæœŸå¹³å‡={second_half_r.mean():.6f}")
    r_trend = (second_half_r.mean() - first_half_r.mean()) / first_half_r.mean() * 100
    print(f"            å˜åŒ–è¶‹åŠ¿: {r_trend:+.2f}%")
    
    # ç¨³å®šæ€§è¯„ä¼°
    print(f"\nâš ï¸  ç¨³å®šæ€§è¯„ä¼°:")
    d_cv = data['loss_d'].std() / data['loss_d'].mean()  # å˜å¼‚ç³»æ•°
    g_cv = data['loss_g_adv'].std() / data['loss_g_adv'].mean()
    r_cv = data['loss_reg'].std() / data['loss_reg'].mean()
    
    print(f"   Loss_D å˜å¼‚ç³»æ•°: {d_cv:.4f} {'âœ“ ç¨³å®š' if d_cv < 0.3 else 'âš ï¸ æ³¢åŠ¨è¾ƒå¤§' if d_cv < 0.5 else 'âŒ éå¸¸ä¸ç¨³å®š'}")
    print(f"   Loss_G_adv å˜å¼‚ç³»æ•°: {g_cv:.4f} {'âœ“ ç¨³å®š' if g_cv < 0.3 else 'âš ï¸ æ³¢åŠ¨è¾ƒå¤§' if g_cv < 0.5 else 'âŒ éå¸¸ä¸ç¨³å®š'}")
    print(f"   Loss_Reg å˜å¼‚ç³»æ•°: {r_cv:.4f} {'âœ“ ç¨³å®š' if r_cv < 0.3 else 'âš ï¸ æ³¢åŠ¨è¾ƒå¤§' if r_cv < 0.5 else 'âŒ éå¸¸ä¸ç¨³å®š'}")
    
    # æ¢¯åº¦çˆ†ç‚¸æ£€æµ‹
    print(f"\nâš¡ å¼‚å¸¸å€¼æ£€æµ‹:")
    d_outliers = np.sum(data['loss_d'] > data['loss_d'].mean() + 3*data['loss_d'].std())
    g_outliers = np.sum(data['loss_g_adv'] > data['loss_g_adv'].mean() + 3*data['loss_g_adv'].std())
    r_outliers = np.sum(data['loss_reg'] > data['loss_reg'].mean() + 3*data['loss_reg'].std())
    
    print(f"   Loss_D å¼‚å¸¸å€¼æ•°: {d_outliers} {'âœ“ æ— ' if d_outliers == 0 else f'âš ï¸ {d_outliers}æ¬¡'}")
    print(f"   Loss_G_adv å¼‚å¸¸å€¼æ•°: {g_outliers} {'âœ“ æ— ' if g_outliers == 0 else f'âš ï¸ {g_outliers}æ¬¡'}")
    print(f"   Loss_Reg å¼‚å¸¸å€¼æ•°: {r_outliers} {'âœ“ æ— ' if r_outliers == 0 else f'âš ï¸ {r_outliers}æ¬¡'}")
    
    # ç»¼åˆåˆ¤æ–­
    print(f"\nğŸ¯ ç»¼åˆåˆ¤æ–­:")
    stability_score = 0
    if d_cv < 0.3 and g_cv < 0.3:
        stability_score += 2
        print("   âœ“ ä¸¤ä¸ªä¸»æŸå¤±å‡½æ•°éƒ½ç›¸å¯¹ç¨³å®š")
    elif d_cv < 0.5 and g_cv < 0.5:
        stability_score += 1
        print("   âš ï¸ ä¸¤ä¸ªä¸»æŸå¤±å‡½æ•°æ³¢åŠ¨ä¸­ç­‰")
    else:
        print("   âŒ ä¸¤ä¸ªä¸»æŸå¤±å‡½æ•°æ³¢åŠ¨è¾ƒå¤§")
    
    if abs(d_trend) < 20 and abs(g_trend) < 20:
        stability_score += 1
        print("   âœ“ æŸå¤±å€¼è¶‹åŠ¿ç¨³å®šï¼Œæ— æ˜æ˜¾æ¶åŒ–")
    elif abs(d_trend) < 40 and abs(g_trend) < 40:
        print("   âš ï¸ æŸå¤±å€¼æœ‰ä¸€å®šæ³¢åŠ¨")
    else:
        print("   âŒ æŸå¤±å€¼è¶‹åŠ¿æ˜æ˜¾æ¶åŒ–")
    
    if d_outliers == 0 and g_outliers == 0:
        stability_score += 1
        print("   âœ“ æ— æ˜æ˜¾æ¢¯åº¦çˆ†ç‚¸ç°è±¡")
    else:
        print(f"   âš ï¸ æ£€æµ‹åˆ° {d_outliers + g_outliers} ä¸ªå¼‚å¸¸å°–å³°")
    
    print(f"\n   ç¨³å®šæ€§è¯„åˆ†: {stability_score}/4")
    if stability_score >= 3:
        print("   ğŸ’š è®­ç»ƒè¾ƒç¨³å®šï¼Œå¯ç»§ç»­")
    elif stability_score >= 2:
        print("   ğŸŸ¡ è®­ç»ƒåŸºæœ¬ç¨³å®šï¼Œä½†éœ€è¦ç›‘æ§")
    else:
        print("   ğŸ”´ è®­ç»ƒä¸ç¨³å®šï¼Œå»ºè®®è°ƒæ•´è¶…å‚æ•°")
    
    print("="*70 + "\n")

def plot_training_curves(data, output_dir):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    fig, axes = plt.subplots(3, 1, figsize=(12, 10))
    
    # Loss_D
    axes[0].plot(data['iterations'], data['loss_d'], linewidth=1.5, label='Loss_D')
    axes[0].set_ylabel('Loss_D', fontsize=12)
    axes[0].set_title('Discriminator Loss', fontsize=14, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    axes[0].legend()
    
    # Loss_G_adv
    axes[1].plot(data['iterations'], data['loss_g_adv'], linewidth=1.5, color='orange', label='Loss_G_adv')
    axes[1].set_ylabel('Loss_G_adv', fontsize=12)
    axes[1].set_title('Generator Adversarial Loss', fontsize=14, fontweight='bold')
    axes[1].grid(True, alpha=0.3)
    axes[1].legend()
    
    # Loss_Reg
    axes[2].plot(data['iterations'], data['loss_reg'], linewidth=1.5, color='green', label='Loss_Reg')
    axes[2].set_ylabel('Loss_Reg', fontsize=12)
    axes[2].set_xlabel('Iteration', fontsize=12)
    axes[2].set_title('Kernel Regularization Loss', fontsize=14, fontweight='bold')
    axes[2].grid(True, alpha=0.3)
    axes[2].legend()
    
    plt.tight_layout()
    output_path = os.path.join(output_dir, 'training_curves.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {output_path}")
    plt.close()

if __name__ == "__main__":
    log_file = r"output\kernelgan_out_denoised_single_kernel\training_log.txt"
    
    data = load_training_log(log_file)
    if data is not None:
        analyze_stability(data)
        
        output_dir = os.path.dirname(log_file)
        plot_training_curves(data, output_dir)
