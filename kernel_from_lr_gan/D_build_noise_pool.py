"""
ä»GOCI-2å»å™ªæ•°æ®ä¸­æ„å»ºå™ªå£°æ± ï¼š
- å™ªå£° = geophysical_data - denoised
- æ¯ä¸ªæ–‡ä»¶éšæœºæŠ½å–æŒ‡å®šæ•°é‡çš„32Ã—32å™ªå£°å—
- ä¿å­˜ä¸º (N, 5, 32, 32) çš„ .npy æ–‡ä»¶

è¿è¡Œç¤ºä¾‹ï¼š
    python kernel_from_lr_gan/build_noise_pool.py
    python kernel_from_lr_gan/build_noise_pool.py --samples_per_file 3 --patch_size 64
"""
import os
import argparse
import random
import numpy as np
from netCDF4 import Dataset
from tqdm import tqdm

# é»˜è®¤é…ç½®
GOCI_DIR = r"H:\GOCI-2\patch_output_nc\patches_denoised"
OUTPUT_FILE = r"H:\GOCI-2\patch_output_nc\noise_pool/goci_noise_pool.npy"
METADATA_FILE = r"H:\GOCI-2\patch_output_nc\noise_pool/goci_noise_metadata.npy"

BAND_NAMES = ['L_TOA_443', 'L_TOA_490', 'L_TOA_555', 'L_TOA_660', 'L_TOA_865']


def load_group_bands(nc_path: str, group_name: str) -> np.ndarray:
    """åŠ è½½æŒ‡å®šç»„çš„5ä¸ªæ³¢æ®µï¼Œè¿”å› (5, H, W)"""
    with Dataset(nc_path, 'r') as ds:
        if group_name not in ds.groups:
            raise ValueError(f"ç»„ {group_name} ä¸å­˜åœ¨äº {nc_path}")
        grp = ds.groups[group_name]
        bands = []
        for b in BAND_NAMES:
            arr = grp.variables[b][:]
            if isinstance(arr, np.ma.MaskedArray):
                arr = arr.filled(np.nan)
            bands.append(np.array(arr, dtype=np.float32))
        return np.stack(bands, axis=0)  # (5, H, W)


def random_crop(data: np.ndarray, crop_size: int, n_samples: int) -> list[np.ndarray]:
    """ä» (C, H, W) ä¸­éšæœºè£å‰ª n_samples ä¸ª (C, crop_size, crop_size) å—"""
    _, H, W = data.shape
    if H < crop_size or W < crop_size:
        raise ValueError(f"å›¾åƒå°ºå¯¸ {H}Ã—{W} å°äºè£å‰ªå°ºå¯¸ {crop_size}")
    
    patches = []
    for _ in range(n_samples):
        top = random.randint(0, H - crop_size)
        left = random.randint(0, W - crop_size)
        patch = data[:, top:top+crop_size, left:left+crop_size]
        patches.append(patch)
    return patches


def build_noise_pool(
    goci_dir: str,
    output_file: str,
    metadata_file: str,
    samples_per_file: int = 1,
    patch_size: int = 32,
    seed: int = 42
):
    """æ„å»ºå™ªå£°æ± """
    random.seed(seed)
    np.random.seed(seed)
    
    if not os.path.isdir(goci_dir):
        raise FileNotFoundError(f"GOCIç›®å½•ä¸å­˜åœ¨: {goci_dir}")
    
    nc_files = [f for f in os.listdir(goci_dir) if f.endswith('.nc')]
    if not nc_files:
        raise FileNotFoundError(f"ç›®å½•ä¸­æ²¡æœ‰.ncæ–‡ä»¶: {goci_dir}")
    
    all_noise_patches = []
    metadata = []  # è®°å½•æ¥æºæ–‡ä»¶å’Œç´¢å¼•
    
    print(f"å¼€å§‹å¤„ç† {len(nc_files)} ä¸ªæ–‡ä»¶ï¼Œæ¯æ–‡ä»¶é‡‡æ · {samples_per_file} ä¸ª {patch_size}Ã—{patch_size} å™ªå£°å—...")
    
    for fname in tqdm(nc_files, desc="æå–å™ªå£°", unit="file"):
        nc_path = os.path.join(goci_dir, fname)
        try:
            # åŠ è½½åŸå§‹å’Œå»å™ªæ•°æ®
            geo_data = load_group_bands(nc_path, 'geophysical_data')  # (5, H, W)
            denoised_data = load_group_bands(nc_path, 'denoised')      # (5, H, W)
            
            # è®¡ç®—å™ªå£°
            noise = geo_data - denoised_data  # (5, H, W)
            
            # éšæœºè£å‰ª
            noise_patches = random_crop(noise, patch_size, samples_per_file)
            all_noise_patches.extend(noise_patches)
            
            # è®°å½•å…ƒæ•°æ®
            for i in range(samples_per_file):
                metadata.append({
                    'source_file': fname,
                    'patch_id': i,
                    'patch_size': patch_size
                })
        
        except Exception as e:
            print(f"\nâš ï¸  å¤„ç† {fname} å¤±è´¥: {e}")
            continue
    
    if not all_noise_patches:
        raise RuntimeError("æœªæˆåŠŸæå–ä»»ä½•å™ªå£°å—")
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„ (N, 5, patch_size, patch_size)
    noise_pool = np.stack(all_noise_patches, axis=0)
    
    # ä¿å­˜
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    np.save(output_file, noise_pool)
    np.save(metadata_file, metadata)
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nâœ… å™ªå£°æ± æ„å»ºå®Œæˆ:")
    print(f"   - æ€»æ ·æœ¬æ•°: {noise_pool.shape[0]}")
    print(f"   - æ•°ç»„å½¢çŠ¶: {noise_pool.shape}")
    print(f"   - æ–‡ä»¶å¤§å°: {os.path.getsize(output_file) / 1024**2:.2f} MB")
    print(f"   - ä¿å­˜è·¯å¾„: {output_file}")
    print(f"   - å…ƒæ•°æ®:   {metadata_file}")
    
    # ç»Ÿè®¡æ¯ä¸ªæ³¢æ®µçš„å™ªå£°ç‰¹æ€§
    print(f"\nğŸ“Š å™ªå£°ç»Ÿè®¡ (å„æ³¢æ®µ):")
    for i, band in enumerate(BAND_NAMES):
        band_noise = noise_pool[:, i, :, :]
        print(f"   {band:12s}: mean={np.nanmean(band_noise):+.6f}, "
              f"std={np.nanstd(band_noise):.6f}, "
              f"min={np.nanmin(band_noise):+.6f}, "
              f"max={np.nanmax(band_noise):+.6f}")


def main():
    parser = argparse.ArgumentParser(description="æ„å»ºGOCI-2å™ªå£°æ± ")
    parser.add_argument('--goci_dir', type=str, default=GOCI_DIR,
                        help='GOCIå»å™ªæ•°æ®ç›®å½•')
    parser.add_argument('--output_file', type=str, default=OUTPUT_FILE,
                        help='è¾“å‡º.npyæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--metadata_file', type=str, default=METADATA_FILE,
                        help='å…ƒæ•°æ®.npyæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--samples_per_file', type=int, default=1,
                        help='æ¯ä¸ªæ–‡ä»¶é‡‡æ ·çš„å™ªå£°å—æ•°é‡')
    parser.add_argument('--patch_size', type=int, default=32,
                        help='å™ªå£°å—å¤§å°ï¼ˆé»˜è®¤32Ã—32ï¼‰')
    parser.add_argument('--seed', type=int, default=42,
                        help='éšæœºç§å­')
    
    args = parser.parse_args()
    
    build_noise_pool(
        goci_dir=args.goci_dir,
        output_file=args.output_file,
        metadata_file=args.metadata_file,
        samples_per_file=args.samples_per_file,
        patch_size=args.patch_size,
        seed=args.seed
    )


if __name__ == "__main__":
    main()
